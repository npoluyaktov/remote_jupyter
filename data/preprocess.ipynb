{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c88784e-7b2f-49bf-8e97-f71f17203f4f",
   "metadata": {},
   "source": [
    "Переделать на кол-во обращений в час\n",
    "\n",
    "https://stats.stackexchange.com/questions/555291/goodness-of-fit-for-presumably-poisson-distributed-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148ca3a2-a347-464c-8f7c-ecd5fa533c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from scipy.stats import kstest\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "import re\n",
    "import jmespath\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987d2254-85cd-4c86-9649-a8c6daab3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_step1():\n",
    "    d = {}\n",
    "    table = pq.read_table('contracts_abi.parquet')\n",
    "    d_list = table.to_pylist()\n",
    "    for el in d_list:\n",
    "        d[el['key']] = json.loads(el['value'])\n",
    "\n",
    "    l = []\n",
    "    modified_d = {}\n",
    "    for k, v in d.items():\n",
    "        v['address'] = k\n",
    "        abi_func_list = [el['name'] for el in v['abi'] if el['type'] in ['function', 'event']]\n",
    "        abi_func_list = list(set(abi_func_list))\n",
    "        words = []\n",
    "        for el in abi_func_list:\n",
    "            words += re.split(r'(?<![A-Z])(?=[A-Z])', el)\n",
    "            inputs = jmespath.search(f\"abi[?name=='{el}'].inputs[*].name\", v)[0]\n",
    "            for i in inputs:\n",
    "                words += re.split(r'(?<![A-Z])(?=[A-Z])', i)\n",
    "        words = [x.replace('_', '') for x in words if x]\n",
    "        v['abi'] = words\n",
    "        l.append(v)\n",
    "        modified_d[k] = {'name': v['name'], 'abi': v['abi']}\n",
    "\n",
    "    df = pd.DataFrame(data=l)\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, 'abi.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3c717c-a76f-4ac7-8349-5cac675aef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_step2():\n",
    "    cursor = duckdb.connect()\n",
    "    cursor.sql(\"create or replace table t_abi as select * from 'abi.parquet'\")\n",
    "    \n",
    "    directory = '.'\n",
    "    event_files = []\n",
    "     \n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and 'events_' in f:\n",
    "            event_files.append(f\"select * from '{f[2:]}'\")\n",
    "    \n",
    "    q = ' union all '.join(event_files)\n",
    "    sql = f'create or replace table t_events as ({q})'\n",
    "    cursor.sql(sql)\n",
    "    \n",
    "    sql = \"\"\"\\\n",
    "    create or replace table t_token_transfers as (\n",
    "    select a.address, a.name, e.event, e.args from t_events e join t_abi a on e.address=a.address where e.event='Transfer')\n",
    "    \"\"\"\n",
    "    cursor.sql(sql)\n",
    "\n",
    "    sql = \"\"\"\\\n",
    "    create or replace table t_edges_weighted as (\n",
    "    select xxx.u, xxx.v, round((xxx.w - min(xxx.w) over ()) / ((max(xxx.w) over ()) - (min(xxx.w) over ())), 3) as norm_w from (\n",
    "    select xx.u, xx.v, sum(xx.w) w from (\n",
    "    select LEAST(x.f, x.t) u, GREATEST(x.f, x.t) v, sum(x.v) w from (\n",
    "    select tt.args->>'from' as f, tt.args->>'to' as t, cast(tt.args->>'value' as INT64) as v from t_token_transfers tt where tt.name='TetherToken'\n",
    "    ) x group by x.f, x.t\n",
    "    ) xx group by xx.u, xx.v\n",
    "    ) xxx\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.sql(sql)\n",
    "    cursor.sql(\"COPY (select * from t_edges_weighted) TO 'edges_weighted.parquet' (FORMAT PARQUET)\")\n",
    "    \n",
    "    sql = \"\"\"\\\n",
    "    create or replace table t_tether_events as (\n",
    "    select e.args->>'from' as fr, e.hash, e.args->>'to' as to, cast(e.args->>'value' as INT64) as v, e.timestamp\n",
    "    from t_events e join t_abi a on e.address=a.address where e.event='Transfer' and a.name='TetherToken'\n",
    "    order by e.timestamp desc\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.sql(sql)\n",
    "    cursor.sql(\"COPY (select * from t_tether_events) TO 'tether_events.parquet' (FORMAT PARQUET)\")\n",
    "    \n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e3b56c0-bc86-45e3-93b0-34fb15c71339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_step3():\n",
    "    cursor = duckdb.connect()\n",
    "    sql = \"select min(timestamp) t_min, max(timestamp) t_max, date_diff('hour', to_timestamp(min(timestamp)), to_timestamp(max(timestamp))) diff from 'tether_events.parquet'\"\n",
    "    row = cursor.sql(sql).fetchall()[0]\n",
    "\n",
    "    sql = \"\"\"\\\n",
    "    create or replace table time_series as (\n",
    "    select tt.ts, \n",
    "    tt.ts + 60*60 - 1 as te,\n",
    "    date_diff('hour', to_timestamp({0}), to_timestamp(tt.ts + 60*60 - 1)) diff\n",
    "    from (\n",
    "    SELECT epoch(t.generate_series)::INTEGER as ts FROM generate_series(to_timestamp({0}), to_timestamp({1}), INTERVAL '1' HOUR) t\n",
    "    ) tt)\n",
    "    \"\"\"\n",
    "    cursor.sql(sql.format(row[0], row[1] - 60*60))\n",
    "\n",
    "    sql = \"\"\"\\\n",
    "    COPY (\n",
    "    with tmp1 as (select t.fr as adr from 'tether_events.parquet' t group by t.fr having count(t.to) > 1),\n",
    "    tmp2 as (select t.to as adr from 'tether_events.parquet' t group by t.to having count(t.fr) > 1),\n",
    "    tmp3 as (select a.adr from tmp1 a join tmp2 b on a.adr=b.adr),\n",
    "    base as (select * from tmp3 cross join time_series),\n",
    "    join_base as (select b.*, e.{0} as adj from base b left join 'tether_events.parquet' e on b.adr=e.{1} and e.timestamp between ts and te),\n",
    "    gr_base as (select adr, diff, sum(CASE WHEN adj is null THEN 0 ELSE 1 END)::integer cnt from join_base group by adr, diff)\n",
    "    select adr, list(cnt) list_cnt, avg(cnt) avg_cnt, stddev(cnt) stdev_cnt from gr_base group by adr) TO 'adr_{2}_freq.parquet' (FORMAT PARQUET)\n",
    "    \"\"\"\n",
    "    cursor.sql(sql.format('to', 'fr', 'output'))\n",
    "    cursor.sql(sql.format('fr', 'to', 'input'))\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "28c7938d-2640-4fae-aea6-0e04e7c0208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_step4():\n",
    "    cursor = duckdb.connect()\n",
    "    sql = \"\"\"\\\n",
    "    COPY (\n",
    "    with base_adr as (select distinct adr from (select a.fr as adr from 'tether_events.parquet' a \n",
    "    union all select b.to as adr from 'tether_events.parquet' b)),\n",
    "    base_type as (select b.adr, a.name from base_adr b left join 'abi.parquet' a on a.address=b.adr),\n",
    "    base_type_counts_out as (select t.fr, \n",
    "                                    count(distinct t.to)::integer cnt_uniq_out, \n",
    "                                    sum(v) sum_out, \n",
    "                                    min(timestamp) min_ts_out,\n",
    "                                    max(timestamp) max_ts_out from 'tether_events.parquet' t group by t.fr),\n",
    "    base_type_counts_in as (select t.to, \n",
    "                                    count(distinct t.fr)::integer cnt_uniq_in, \n",
    "                                    sum(v) sum_in,\n",
    "                                    min(timestamp) min_ts_in,\n",
    "                                    max(timestamp) max_ts_in from 'tether_events.parquet' t group by t.to),\n",
    "    base_total as (select x.*, y.cnt_uniq_out, y.sum_out, z.cnt_uniq_in, z.sum_in, (greatest(y.max_ts_out, z.max_ts_in) - least(y.min_ts_out, z.min_ts_in)) lifetime from \n",
    "        base_type x left join base_type_counts_out y on x.adr=y.fr\n",
    "        left join base_type_counts_in z on x.adr=z.to)\n",
    "    select x.*, \n",
    "    round(y.avg_cnt, 2) avg_cnt_out, round(z.avg_cnt, 2) avg_cnt_in,\n",
    "    round(y.stdev_cnt, 2) stdev_cnt_out, round(z.stdev_cnt, 2) stdev_cnt_in, \n",
    "    (CASE WHEN x.name is null THEN 'wallet' ELSE 'contract' END) adr_type from base_total x \n",
    "    left join 'adr_output_freq.parquet' y on x.adr=y.adr\n",
    "    left join 'adr_input_freq.parquet' z on x.adr=z.adr) TO 'tether_dataset.parquet' (FORMAT PARQUET)\n",
    "    \"\"\"\n",
    "    cursor.sql(sql)\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97b54df9-3634-4266-8986-6d9fe03d67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_step4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "779354c3-0d02-42e4-9f4b-bc5ac6c3d038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ac116-1819-44a2-8ccd-a9d3a7832ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
